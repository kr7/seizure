{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr7/seizure/blob/main/SeizureDetection_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSAzuUhxf86"
      },
      "source": [
        "**Enhanced ROCKET for Automated Detection of Epileptic Tonic-Clonic Seizure Using Accelerometer Data**\n",
        "\n",
        "This notebook contains the implementation of the baselines (MLP, CNN, FCN and ResNet) used in the above paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ziwkrzZXJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from numpy import random as rnd\n",
        "from scipy.io import arff\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental Settings**"
      ],
      "metadata": {
        "id": "w12FnQJlgqPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2Q_XWEN3Qs1"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" # may be set to \"cpu\" if calculations are not expected to be performed on GPU\n",
        "backbone = \"ResNet\" # may be set to MLP, CNN, FCN or ResNet\n",
        "epochs = 1000 # 100 for OpenSeizure data\n",
        "LR = 1e-5 # 1e-4 for OpenSeizure data\n",
        "batchsize = 16 # 32 for OpenSeizure data\n",
        "\n",
        "dataset = \"Epilepsy\"\n",
        "# dataset may be set to \"Epilepsy\" or \"OpenSeizure\"\n",
        "# - \"Epilepsy\" denotes the dataset that is publicly available from\n",
        "#   https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip\n",
        "# - If you want to use the \"OpenSeizure\" data, you should first execute\n",
        "#   the script to preprocess data. This notebook will ask you to upload\n",
        "#   the preprocessed data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the data**"
      ],
      "metadata": {
        "id": "gGwT7GYtgt-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQbg8phDt22r"
      },
      "outputs": [],
      "source": [
        "if dataset == \"Epilepsy\":\n",
        "  os.system(\"wget https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip\")\n",
        "  os.system(\"unzip -q Epilepsy.zip\")\n",
        "\n",
        "  # In order to perform 10-fold cross-validation, we\n",
        "  # will merge the provided train and test splits and\n",
        "  # we will split the data durign the cross-validation\n",
        "\n",
        "  NUM_CLASSES = 4\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for filename in ['Epilepsy_TRAIN.arff', 'Epilepsy_TEST.arff' ]:\n",
        "    raw_data = arff.loadarff(filename)\n",
        "\n",
        "    nextInstance = True\n",
        "    i = 0\n",
        "\n",
        "    while nextInstance:\n",
        "      try:\n",
        "        dim1 = list(raw_data[0][i][0][0])\n",
        "        dim2 = list(raw_data[0][i][0][1])\n",
        "        dim3 = list(raw_data[0][i][0][2])\n",
        "        label = raw_data[0][i][1]\n",
        "\n",
        "        X.append([dim1,dim2,dim3])\n",
        "        if label == b'EPILEPSY':\n",
        "          label = 0\n",
        "        elif label == b'WALKING':\n",
        "          label = 1\n",
        "        elif label == b'RUNNING':\n",
        "          label = 2\n",
        "        elif label == b'SAWING':\n",
        "          label = 3\n",
        "        else:\n",
        "          print(f'Unexpected label: {label}')\n",
        "        y.append(label)\n",
        "\n",
        "        i = i+1\n",
        "      except:\n",
        "        nextInstance = False\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "elif dataset == \"OpenSeizure\":\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  # Read (preprocessed) OpenSeizure data\n",
        "\n",
        "  NUM_CLASSES = 2\n",
        "  NUM_CHANNELS = 3\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  with open('OpenSeizure.txt', 'r') as f:\n",
        "    nextInstance = True\n",
        "    while nextInstance:\n",
        "      try:\n",
        "        dim1 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        dim2 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        dim3 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        label = int(f.readline())\n",
        "\n",
        "        X.append([dim1,dim2,dim3])\n",
        "        y.append(label)\n",
        "      except:\n",
        "        nextInstance = False\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "else:\n",
        "  raise Exception(f\"Unknown dataset: {dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment**"
      ],
      "metadata": {
        "id": "yxt6hC_Kgy6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqB_9i_z3laa"
      },
      "outputs": [],
      "source": [
        "NUM_INSTANCES, NUM_CHANNELS, LENGTH = np.shape(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ18Ds5YjR1d"
      },
      "outputs": [],
      "source": [
        "class FCN(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = NUM_CHANNELS, out_channels = 128,\n",
        "                                kernel_size=8, padding = 0, stride = 1)\n",
        "        self.conv2 = nn.Conv1d(in_channels = 128, out_channels = 256,\n",
        "                               kernel_size=5, padding = 0, stride = 1)\n",
        "        self.conv3 = nn.Conv1d(in_channels = 256, out_channels = 128,\n",
        "                               kernel_size=3, padding = 0, stride = 1)\n",
        "        self.out = nn.Linear(128, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Global Average Pooling (GAP)\n",
        "        x = torch.mean(x, 2)\n",
        "        x = x.view(-1, 128)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = NUM_CHANNELS, out_channels = 16,\n",
        "                                kernel_size=32, padding = 0, stride = 1)\n",
        "\n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(16*(LENGTH - 31), 32)\n",
        "\n",
        "        self.out = nn.Linear(32, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # fully connected layer\n",
        "        x = x.view(-1, 16*(LENGTH - 31))\n",
        "        x = self.fc(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(NUM_CHANNELS*LENGTH, 100) # fully connected layer\n",
        "        self.out = nn.Linear(100, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS*LENGTH)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def convolution(in_channels, out_channels, kernel_size, padding=\"same\", device=\"cpu\"):\n",
        "  return nn.Conv1d(in_channels=in_channels, out_channels=out_channels,\n",
        "                   kernel_size=kernel_size, padding=padding, stride=1)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, device=\"cpu\"):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv11 = convolution(NUM_CHANNELS, 64, 8, device=device)\n",
        "        self.conv12 = convolution(64, 64, 5, device=device)\n",
        "        self.conv13 = convolution(64, 64, 3, device=device)\n",
        "        self.fit_dimensions = convolution(NUM_CHANNELS, 64, 1, device=device)\n",
        "\n",
        "        self.conv21 = convolution(64, 128, 8, device=device)\n",
        "        self.conv22 = convolution(128, 128, 5, device=device)\n",
        "        self.conv23 = convolution(128, 128, 3, device=device)\n",
        "\n",
        "        self.conv31 = convolution(128, 128, 8, device=device)\n",
        "        self.conv32 = convolution(128, 128, 5, device=device)\n",
        "        self.conv33 = convolution(128, 128, 3, device=device)\n",
        "\n",
        "        self.out = nn.Linear(128, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv11(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = torch.relu(x)\n",
        "        x1 = self.fit_dimensions(x1)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv21(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv22(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv23(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = torch.cat( (x1,x1), 1)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv31(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv32(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv33(x)\n",
        "        x = torch.relu(x)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Global Average Pooling (GAP)\n",
        "        x = torch.mean(x, 2)\n",
        "        x = x.view(-1, 128)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEwvPNM5IY0s"
      },
      "outputs": [],
      "source": [
        "def evaluate(pred, y_test):\n",
        "  err = np.mean(pred != y_test)\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == 0 and y_test[i] == 0:\n",
        "      tp = tp+1\n",
        "    elif pred[i] == 0 and y_test[i] != 0:\n",
        "      fp = fp+1\n",
        "    elif pred[i] != 0 and y_test[i] == 0:\n",
        "      fn = fn+1\n",
        "    elif pred[i] != 0 and y_test[i] != 0:\n",
        "      tn = tn+1\n",
        "    else:\n",
        "      raise Exception(\"Bug!\")\n",
        "\n",
        "  if tp == 0:\n",
        "    prec = 0\n",
        "    recall = 0\n",
        "  else:\n",
        "    prec = tp / (tp+fp)\n",
        "    recall = tp / (tp+fn)\n",
        "  if (prec == 0) and (recall == 0):\n",
        "    f1 = 0\n",
        "  else:\n",
        "    f1 = 2*prec*recall/(prec+recall)\n",
        "\n",
        "  return err, prec, recall, f1, tp, fp, tn, fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI9qXl_IcVca"
      },
      "outputs": [],
      "source": [
        "# 10-times 10-fold cross-validation\n",
        "\n",
        "all_err = np.zeros( (8,100) )\n",
        "all_loss = []\n",
        "fold = 0\n",
        "\n",
        "for seed in range(10):\n",
        "  kf = StratifiedKFold(n_splits=10, random_state=seed+42, shuffle=True)\n",
        "  for train_index, test_index in kf.split(X, y):\n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    y_train = y[train_index]\n",
        "    y_test  = y[test_index]\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(\n",
        "      torch.Tensor(X_train), torch.LongTensor(y_train) )\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "      train_dataset, shuffle=True, batch_size=batchsize)\n",
        "\n",
        "    if backbone == \"FCN\":\n",
        "      model = FCN(device=device)\n",
        "    elif backbone == \"ResNet\":\n",
        "      model = ResNet(device=device)\n",
        "    elif backbone == \"CNN\":\n",
        "      model = CNN(device=device)\n",
        "    elif backbone == \"MLP\":\n",
        "      model = MLP(device=device)\n",
        "    else:\n",
        "      raise Exception(f\"Unknown backbone: {backbone}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_n = 0\n",
        "        for input_batch, target_batch in trainloader:\n",
        "            input_batch = input_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            prediction_batch = model(input_batch)\n",
        "\n",
        "            loss = criterion(prediction_batch, target_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_n = running_n + 1\n",
        "\n",
        "        all_loss.append(running_loss/running_n)\n",
        "\n",
        "    test_dataset = torch.utils.data.TensorDataset(\n",
        "        torch.Tensor(X_test), torch.LongTensor(y_test) )\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset)\n",
        "\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            pred.append(int(predicted.cpu()[0]))\n",
        "\n",
        "    all_err[:,fold] = evaluate(pred, y_test)\n",
        "    print(f\"{fold:3}  {all_err[0,fold]} \")\n",
        "\n",
        "    fold = fold + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**"
      ],
      "metadata": {
        "id": "vxnJM2O-g6NY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9LuSRVDh1fc"
      },
      "outputs": [],
      "source": [
        "print( \"Method  epochs  LR     Classification err Precision          Recall             F1\")\n",
        "print(f\"{backbone:6}    {epochs:4} {LR:6}  \"+\n",
        "      f\"{np.mean(all_err[0]):6.4f} +/- {np.std(all_err[0]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[1]):6.4f} +/- {np.std(all_err[1]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[2]):6.4f} +/- {np.std(all_err[2]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[3]):6.4f} +/- {np.std(all_err[3]):6.4f}  \"+\n",
        "      f\"{np.sum(all_err[4]):4}   \"+\n",
        "      f\"{np.sum(all_err[5]):4}   \"+\n",
        "      f\"{np.sum(all_err[6]):4}   \"+\n",
        "      f\"{np.sum(all_err[7]):4}   \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn3qcmL3rGqq"
      },
      "outputs": [],
      "source": [
        "# Just to check if the model converged nicely\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_loss[0:epochs]);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM+w2lakfJJdv602d2qiLIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}