{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr7/seizure/blob/main/SeizureDetection_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSAzuUhxf86"
      },
      "source": [
        "**Enhanced ROCKET for Automated Detection of Epileptic Tonic-Clonic Seizure Using Accelerometer Data**\n",
        "\n",
        "This notebook contains the implementation of the baselines (MLP, CNN, FCN and ResNet) used in the above paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ziwkrzZXJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from numpy import random as rnd\n",
        "from scipy.io import arff\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental Settings**"
      ],
      "metadata": {
        "id": "w12FnQJlgqPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2Q_XWEN3Qs1"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" # may be set to \"cpu\" if calculations are not expected to be performed on GPU\n",
        "backbone = \"FCN\" # may be set to MLP, CNN, FCN or ResNet\n",
        "epochs = 1000 # 100 for OpenSeizure data\n",
        "LR = 1e-5 # 1e-4 for OpenSeizure data\n",
        "batchsize = 16 # 32 for OpenSeizure data\n",
        "\n",
        "dataset = \"Epilepsy\"\n",
        "# dataset may be set to \"Epilepsy\" or \"OpenSeizure\"\n",
        "# - \"Epilepsy\" denotes the dataset that is publicly available from\n",
        "#   https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip\n",
        "# - If you want to use the \"OpenSeizure\" data, you should first execute\n",
        "#   the script to preprocess data. This notebook will ask you to upload\n",
        "#   the preprocessed data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the data**"
      ],
      "metadata": {
        "id": "gGwT7GYtgt-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQbg8phDt22r"
      },
      "outputs": [],
      "source": [
        "if dataset == \"Epilepsy\":\n",
        "  os.system(\"wget https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip\")\n",
        "  os.system(\"unzip -q Epilepsy.zip\")\n",
        "\n",
        "  # In order to perform 10-fold cross-validation, we\n",
        "  # will merge the provided train and test splits and\n",
        "  # we will split the data durign the cross-validation\n",
        "\n",
        "  NUM_CLASSES = 4\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for filename in ['Epilepsy_TRAIN.arff', 'Epilepsy_TEST.arff' ]:\n",
        "    raw_data = arff.loadarff(filename)\n",
        "\n",
        "    nextInstance = True\n",
        "    i = 0\n",
        "\n",
        "    while nextInstance:\n",
        "      try:\n",
        "        dim1 = list(raw_data[0][i][0][0])\n",
        "        dim2 = list(raw_data[0][i][0][1])\n",
        "        dim3 = list(raw_data[0][i][0][2])\n",
        "        label = raw_data[0][i][1]\n",
        "\n",
        "        X.append([dim1,dim2,dim3])\n",
        "        if label == b'EPILEPSY':\n",
        "          label = 0\n",
        "        elif label == b'WALKING':\n",
        "          label = 1\n",
        "        elif label == b'RUNNING':\n",
        "          label = 2\n",
        "        elif label == b'SAWING':\n",
        "          label = 3\n",
        "        else:\n",
        "          print(f'Unexpected label: {label}')\n",
        "        y.append(label)\n",
        "\n",
        "        i = i+1\n",
        "      except:\n",
        "        nextInstance = False\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "elif dataset == \"OpenSeizure\":\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  # Read (preprocessed) OpenSeizure data\n",
        "\n",
        "  NUM_CLASSES = 2\n",
        "  NUM_CHANNELS = 3\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  with open('OpenSeizure.txt', 'r') as f:\n",
        "    nextInstance = True\n",
        "    while nextInstance:\n",
        "      try:\n",
        "        dim1 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        dim2 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        dim3 = [ float(v) for v in f.readline().split(\",\")]\n",
        "        label = int(f.readline())\n",
        "\n",
        "        X.append([dim1,dim2,dim3])\n",
        "        y.append(label)\n",
        "      except:\n",
        "        nextInstance = False\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "else:\n",
        "  raise Exception(f\"Unknown dataset: {dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment**"
      ],
      "metadata": {
        "id": "yxt6hC_Kgy6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqB_9i_z3laa"
      },
      "outputs": [],
      "source": [
        "NUM_INSTANCES, NUM_CHANNELS, LENGTH = np.shape(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ18Ds5YjR1d"
      },
      "outputs": [],
      "source": [
        "class FCN(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = NUM_CHANNELS, out_channels = 128,\n",
        "                                kernel_size=8, padding = 0, stride = 1)\n",
        "        self.conv2 = nn.Conv1d(in_channels = 128, out_channels = 256,\n",
        "                               kernel_size=5, padding = 0, stride = 1)\n",
        "        self.conv3 = nn.Conv1d(in_channels = 256, out_channels = 128,\n",
        "                               kernel_size=3, padding = 0, stride = 1)\n",
        "        self.out = nn.Linear(128, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Global Average Pooling (GAP)\n",
        "        x = torch.mean(x, 2)\n",
        "        x = x.view(-1, 128)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = NUM_CHANNELS, out_channels = 16,\n",
        "                                kernel_size=32, padding = 0, stride = 1)\n",
        "\n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(16*(LENGTH - 31), 32)\n",
        "\n",
        "        self.out = nn.Linear(32, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # fully connected layer\n",
        "        x = x.view(-1, 16*(LENGTH - 31))\n",
        "        x = self.fc(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(NUM_CHANNELS*LENGTH, 100) # fully connected layer\n",
        "        self.out = nn.Linear(100, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,  NUM_CHANNELS*LENGTH)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def convolution(in_channels, out_channels, kernel_size, padding=\"same\", device=\"cpu\"):\n",
        "  return nn.Conv1d(in_channels=in_channels, out_channels=out_channels,\n",
        "                   kernel_size=kernel_size, padding=padding, stride=1)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, device=\"cpu\"):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv11 = convolution(NUM_CHANNELS, 64, 8, device=device)\n",
        "        self.conv12 = convolution(64, 64, 5, device=device)\n",
        "        self.conv13 = convolution(64, 64, 3, device=device)\n",
        "        self.fit_dimensions = convolution(NUM_CHANNELS, 64, 1, device=device)\n",
        "\n",
        "        self.conv21 = convolution(64, 128, 8, device=device)\n",
        "        self.conv22 = convolution(128, 128, 5, device=device)\n",
        "        self.conv23 = convolution(128, 128, 3, device=device)\n",
        "\n",
        "        self.conv31 = convolution(128, 128, 8, device=device)\n",
        "        self.conv32 = convolution(128, 128, 5, device=device)\n",
        "        self.conv33 = convolution(128, 128, 3, device=device)\n",
        "\n",
        "        self.out = nn.Linear(128, NUM_CLASSES)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, NUM_CHANNELS, LENGTH)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv11(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = torch.relu(x)\n",
        "        x1 = self.fit_dimensions(x1)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv21(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv22(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv23(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = torch.cat( (x1,x1), 1)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x1 = x\n",
        "        x = self.conv31(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv32(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv33(x)\n",
        "        x = torch.relu(x)\n",
        "        x = x + x1\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Global Average Pooling (GAP)\n",
        "        x = torch.mean(x, 2)\n",
        "        x = x.view(-1, 128)\n",
        "\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ShapeFormer(nn.Module):\n",
        "    \"\"\"\n",
        "    Lightweight ShapeFormer-like transformer for time-series classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 device=\"cpu\",\n",
        "                 d_model: int = 128,\n",
        "                 n_heads: int = 8,\n",
        "                 mlp_dim: int = 256,\n",
        "                 num_layers: int = 3,\n",
        "                 patch_size: int = 4,\n",
        "                 dropout: float = 0.1):\n",
        "        super(ShapeFormer, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.d_model = d_model\n",
        "        self.patch_size = max(1, int(patch_size))\n",
        "\n",
        "        # Patch embedding: a small conv that maps NUM_CHANNELS -> d_model and downsamples (stride=patch_size)\n",
        "        # Input will be (batch, NUM_CHANNELS, LENGTH)\n",
        "        self.patch_embed = nn.Conv1d(in_channels=NUM_CHANNELS,\n",
        "                                     out_channels=d_model,\n",
        "                                     kernel_size=self.patch_size,\n",
        "                                     stride=self.patch_size,\n",
        "                                     padding=0,\n",
        "                                     bias=True)\n",
        "\n",
        "        # We'll compute seq_len after one forward, but create a small max positional embedding\n",
        "        # to cover reasonable LENGTH values. We be safe and allow up to LENGTH tokens.\n",
        "        # Effective max tokens = ceil(LENGTH/patch_size)\n",
        "        max_tokens = (LENGTH + self.patch_size - 1) // self.patch_size\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, max_tokens, d_model))  # (1, seq_len, d_model)\n",
        "\n",
        "        # Transformer-style encoder: small stack of MHA + MLP with LayerNorm + residuals\n",
        "        self.num_layers = num_layers\n",
        "        self.attn_layers = nn.ModuleList([\n",
        "            nn.MultiheadAttention(embed_dim=d_model, num_heads=n_heads, dropout=dropout, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm1 = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(num_layers)])\n",
        "        self.norm2 = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(num_layers)])\n",
        "        self.ffn = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(d_model, mlp_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(mlp_dim, d_model),\n",
        "                nn.Dropout(dropout),\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # final classifier head\n",
        "        self.classifier = nn.Linear(d_model, NUM_CLASSES)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # Init weights (small init for stability)\n",
        "        self._init_weights()\n",
        "\n",
        "        # send to device\n",
        "        self.to(device)\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.xavier_uniform_(self.patch_embed.weight)\n",
        "        if self.patch_embed.bias is not None:\n",
        "            nn.init.constant_(self.patch_embed.bias, 0.0)\n",
        "        for m in self.ffn:\n",
        "            for layer in m:\n",
        "                if isinstance(layer, nn.Linear):\n",
        "                    nn.init.xavier_uniform_(layer.weight)\n",
        "                    if layer.bias is not None:\n",
        "                        nn.init.constant_(layer.bias, 0.0)\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        if self.classifier.bias is not None:\n",
        "            nn.init.constant_(self.classifier.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure same input reshaping convention as your other models\n",
        "        # x could come in as (batch, LENGTH, NUM_CHANNELS) or (batch, NUM_CHANNELS*LENGTH) depending on upstream.\n",
        "        # Existing models call x.view(-1, NUM_CHANNELS, LENGTH) so we mirror that:\n",
        "        x = x.view(-1, NUM_CHANNELS, LENGTH)   # (B, C, L)\n",
        "\n",
        "        # Patch embedding\n",
        "        # patch_embed conv output shape: (B, d_model, seq_len)\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        # transpose to (B, seq_len, d_model)\n",
        "        x = x.permute(0, 2, 1).contiguous()\n",
        "\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # Add positional embeddings (slice to seq_len)\n",
        "        if seq_len <= self.pos_embed.shape[1]:\n",
        "            pos = self.pos_embed[:, :seq_len, :]\n",
        "        else:\n",
        "            # If input has more tokens than our pre-allocated pos_embed (rare), tile / interpolate:\n",
        "            # Simple tiling: repeat the learned pos embeddings - keeps things stable and cheap.\n",
        "            repeats = (seq_len + self.pos_embed.shape[1] - 1) // self.pos_embed.shape[1]\n",
        "            pos = self.pos_embed.repeat(1, repeats, 1)[:, :seq_len, :]\n",
        "\n",
        "        x = x + pos  # (B, seq_len, d_model)\n",
        "\n",
        "        # Transformer encoder stack (batch_first=True used in MultiheadAttention)\n",
        "        for i in range(self.num_layers):\n",
        "            # Pre-norm + MHA with residual\n",
        "            x_norm = self.norm1[i](x)\n",
        "            # MultiheadAttention expects (B, seq_len, embed) when batch_first=True\n",
        "            attn_out, _ = self.attn_layers[i](x_norm, x_norm, x_norm, need_weights=False)\n",
        "            x = x + attn_out  # residual\n",
        "\n",
        "            # FFN with residual\n",
        "            x_norm = self.norm2[i](x)\n",
        "            ffn_out = self.ffn[i](x_norm)\n",
        "            x = x + ffn_out\n",
        "\n",
        "        # Global average pooling over sequence dimension -> (B, d_model)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # classification\n",
        "        x = self.classifier(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PRSRN5Cd20jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEwvPNM5IY0s"
      },
      "outputs": [],
      "source": [
        "def evaluate(pred, y_test):\n",
        "  err = np.mean(pred != y_test)\n",
        "  tp, tn, fp, fn = 0, 0, 0, 0\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == 0 and y_test[i] == 0:\n",
        "      tp = tp+1\n",
        "    elif pred[i] == 0 and y_test[i] != 0:\n",
        "      fp = fp+1\n",
        "    elif pred[i] != 0 and y_test[i] == 0:\n",
        "      fn = fn+1\n",
        "    elif pred[i] != 0 and y_test[i] != 0:\n",
        "      tn = tn+1\n",
        "    else:\n",
        "      raise Exception(\"Bug!\")\n",
        "\n",
        "  if tp == 0:\n",
        "    prec = 0\n",
        "    recall = 0\n",
        "  else:\n",
        "    prec = tp / (tp+fp)\n",
        "    recall = tp / (tp+fn)\n",
        "  if (prec == 0) and (recall == 0):\n",
        "    f1 = 0\n",
        "  else:\n",
        "    f1 = 2*prec*recall/(prec+recall)\n",
        "\n",
        "  return err, prec, recall, f1, tp, fp, tn, fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI9qXl_IcVca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5e1a8f-985f-4253-db7f-69d220278e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0  0.03571428571428571 \n",
            "  1  0.03571428571428571 \n",
            "  2  0.0 \n",
            "  3  0.0 \n",
            "  4  0.0 \n",
            "  5  0.037037037037037035 \n",
            "  6  0.07407407407407407 \n",
            "  7  0.0 \n",
            "  8  0.07407407407407407 \n",
            "  9  0.07407407407407407 \n",
            " 10  0.03571428571428571 \n",
            " 11  0.03571428571428571 \n",
            " 12  0.0 \n",
            " 13  0.03571428571428571 \n",
            " 14  0.03571428571428571 \n",
            " 15  0.037037037037037035 \n",
            " 16  0.0 \n",
            " 17  0.07407407407407407 \n",
            " 18  0.07407407407407407 \n",
            " 19  0.037037037037037035 \n",
            " 20  0.0 \n",
            " 21  0.07142857142857142 \n",
            " 22  0.03571428571428571 \n",
            " 23  0.03571428571428571 \n",
            " 24  0.07142857142857142 \n",
            " 25  0.037037037037037035 \n",
            " 26  0.0 \n",
            " 27  0.0 \n",
            " 28  0.0 \n",
            " 29  0.07407407407407407 \n",
            " 30  0.0 \n",
            " 31  0.03571428571428571 \n",
            " 32  0.07142857142857142 \n",
            " 33  0.03571428571428571 \n",
            " 34  0.03571428571428571 \n",
            " 35  0.1111111111111111 \n",
            " 36  0.0 \n",
            " 37  0.037037037037037035 \n",
            " 38  0.0 \n",
            " 39  0.037037037037037035 \n",
            " 40  0.03571428571428571 \n",
            " 41  0.10714285714285714 \n",
            " 42  0.03571428571428571 \n",
            " 43  0.03571428571428571 \n",
            " 44  0.0 \n",
            " 45  0.0 \n",
            " 46  0.07407407407407407 \n",
            " 47  0.0 \n",
            " 48  0.0 \n",
            " 49  0.0 \n",
            " 50  0.03571428571428571 \n",
            " 51  0.03571428571428571 \n",
            " 52  0.07142857142857142 \n",
            " 53  0.03571428571428571 \n",
            " 54  0.0 \n",
            " 55  0.037037037037037035 \n",
            " 56  0.037037037037037035 \n",
            " 57  0.1111111111111111 \n",
            " 58  0.0 \n",
            " 59  0.037037037037037035 \n",
            " 60  0.0 \n",
            " 61  0.0 \n",
            " 62  0.10714285714285714 \n",
            " 63  0.0 \n",
            " 64  0.03571428571428571 \n",
            " 65  0.0 \n",
            " 66  0.0 \n",
            " 67  0.1111111111111111 \n",
            " 68  0.037037037037037035 \n",
            " 69  0.037037037037037035 \n",
            " 70  0.07142857142857142 \n",
            " 71  0.0 \n",
            " 72  0.0 \n",
            " 73  0.0 \n",
            " 74  0.03571428571428571 \n",
            " 75  0.07407407407407407 \n",
            " 76  0.0 \n",
            " 77  0.037037037037037035 \n",
            " 78  0.0 \n",
            " 79  0.07407407407407407 \n",
            " 80  0.0 \n",
            " 81  0.10714285714285714 \n",
            " 82  0.03571428571428571 \n",
            " 83  0.0 \n",
            " 84  0.0 \n",
            " 85  0.037037037037037035 \n",
            " 86  0.07407407407407407 \n",
            " 87  0.037037037037037035 \n",
            " 88  0.037037037037037035 \n",
            " 89  0.0 \n",
            " 90  0.0 \n",
            " 91  0.03571428571428571 \n",
            " 92  0.07142857142857142 \n",
            " 93  0.03571428571428571 \n",
            " 94  0.0 \n",
            " 95  0.07407407407407407 \n",
            " 96  0.037037037037037035 \n",
            " 97  0.07407407407407407 \n",
            " 98  0.0 \n",
            " 99  0.037037037037037035 \n"
          ]
        }
      ],
      "source": [
        "# 10-times 10-fold cross-validation\n",
        "\n",
        "all_err = np.zeros( (8,100) )\n",
        "all_loss = []\n",
        "fold = 0\n",
        "\n",
        "for seed in range(10):\n",
        "  kf = StratifiedKFold(n_splits=10, random_state=seed+42, shuffle=True)\n",
        "  for train_index, test_index in kf.split(X, y):\n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    y_train = y[train_index]\n",
        "    y_test  = y[test_index]\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(\n",
        "      torch.Tensor(X_train), torch.LongTensor(y_train) )\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "      train_dataset, shuffle=True, batch_size=batchsize)\n",
        "\n",
        "    if backbone == \"FCN\":\n",
        "      model = FCN(device=device)\n",
        "    elif backbone == \"ResNet\":\n",
        "      model = ResNet(device=device)\n",
        "    elif backbone == \"CNN\":\n",
        "      model = CNN(device=device)\n",
        "    elif backbone == \"MLP\":\n",
        "      model = MLP(device=device)\n",
        "    elif backbone == \"ShapeFormer\":\n",
        "      model = ShapeFormer(device=device)\n",
        "    else:\n",
        "      raise Exception(f\"Unknown backbone: {backbone}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_n = 0\n",
        "        for input_batch, target_batch in trainloader:\n",
        "            input_batch = input_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            prediction_batch = model(input_batch)\n",
        "\n",
        "            loss = criterion(prediction_batch, target_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_n = running_n + 1\n",
        "\n",
        "        all_loss.append(running_loss/running_n)\n",
        "\n",
        "    test_dataset = torch.utils.data.TensorDataset(\n",
        "        torch.Tensor(X_test), torch.LongTensor(y_test) )\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset)\n",
        "\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            pred.append(int(predicted.cpu()[0]))\n",
        "\n",
        "    all_err[:,fold] = evaluate(pred, y_test)\n",
        "    print(f\"{fold:3}  {all_err[0,fold]} \")\n",
        "\n",
        "    fold = fold + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**"
      ],
      "metadata": {
        "id": "vxnJM2O-g6NY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9LuSRVDh1fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4aeaec-1c5f-41e6-dfc4-fe8db96e21e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method  epochs  LR     Classification err Precision          Recall             F1\n",
            "FCN       1000  1e-05  0.0339 +/- 0.0323  0.9476 +/- 0.0809  0.9350 +/- 0.0910  0.9369 +/- 0.0637  636.0   41.0   2029.0   44.0   \n"
          ]
        }
      ],
      "source": [
        "print( \"Method  epochs  LR     Classification err Precision          Recall             F1\")\n",
        "print(f\"{backbone:6}    {epochs:4} {LR:6}  \"+\n",
        "      f\"{np.mean(all_err[0]):6.4f} +/- {np.std(all_err[0]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[1]):6.4f} +/- {np.std(all_err[1]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[2]):6.4f} +/- {np.std(all_err[2]):6.4f}  \"+\n",
        "      f\"{np.mean(all_err[3]):6.4f} +/- {np.std(all_err[3]):6.4f}  \"+\n",
        "      f\"{np.sum(all_err[4]):4}   \"+\n",
        "      f\"{np.sum(all_err[5]):4}   \"+\n",
        "      f\"{np.sum(all_err[6]):4}   \"+\n",
        "      f\"{np.sum(all_err[7]):4}   \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn3qcmL3rGqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "6ccce026-73e6-4c8b-fec0-e6fdd1e12c6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Just to check if the model converged nicely\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_loss[1:epochs]);"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCNo42fEZgG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igbfymedYpXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOUJtashEppzGetJjm+rBgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}